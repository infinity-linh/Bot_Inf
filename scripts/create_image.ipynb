{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness(img, alpha, beta):\n",
    "    img_new = np.asarray(alpha*img + beta, dtype=int)   # cast pixel values to int\n",
    "    img_new[img_new>255] = 255\n",
    "    img_new[img_new<0] = 0\n",
    "    return np.array(img_new, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_eye_left_1 = cv2.imread(\"D:/User/ESP32_DOIT/scripts/kitchenrobot.jpg\")\n",
    "image_eye_left_2 = cv2.imread(\"D:/User/ESP32_DOIT/scripts/smilerobot.jpg\")\n",
    "image_eye_left_1 = cv2.resize(image_eye_left_1, [523,630])\n",
    "image_eye_left_2 = cv2.resize(image_eye_left_2, [523,630])\n",
    "\n",
    "print(image_eye_left_1.shape)\n",
    "print(image_eye_left_2.shape)\n",
    "# image_processed = change_brightness(image, 1, 35)\n",
    "eyes = cv2.hconcat([image_eye_left_1, image_eye_left_2])\n",
    "\n",
    "cv2.imshow(\"image\", eyes)\n",
    "cv2.imwrite(\"imagerobot.png\", eyes)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'D:/User/ESP32_DOIT/scripts/image_102.txt'\n",
    "# read text file into pandas DataFrame\n",
    "df = pd.read_csv(path, sep=\" \", header=None)\n",
    "\n",
    "# display DataFrame\n",
    "print(df[0])\n",
    "for i in range(len(df[0])):\n",
    "    df[0][i] = 45\n",
    "    \n",
    "\n",
    "print(df[0])\n",
    "df.to_csv(path, sep=' ', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "         'hair drier', 'toothbrush' ]\n",
    "names[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "box1 = [100,100,100,100]\n",
    "box2 = [100,100,100,100]\n",
    "state = [0,0,0,0]\n",
    "df = pd.read_csv(\"D:/User/Bot_C/Res/scripts/control.csv\")\n",
    "if df.empty:\n",
    "    print('DataFrame is empty!')\n",
    "data_frame = []\n",
    "# # data_frame.append(box1)\n",
    "data_frame.append(box2)\n",
    "data_frame.append(state)\n",
    "data_frame = np.reshape(data_frame, (1,8))\n",
    "\n",
    "# # df2 = pd.DataFrame(data_frame, columns=['x1', 'x2', 'x3', 'x4',\n",
    "# #                                         'y1', 'y2', 'y3', 'y4',\n",
    "# #                                         'q1', 'q2', 'q3', 'q4'])\n",
    "df2 = pd.DataFrame(data_frame, columns=['c11', 'c12', 'c21', 'c22', 'q1', 'q2', 'q3', 'q4'])\n",
    "\n",
    "# df2 = pd.concat([df,df2])\n",
    "df2.to_csv(\"D:/User/Bot_C/Res/scripts/control.csv\", index=False)\n",
    "\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import torch\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.liner1 = nn.Linear(8,128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.liner2 = nn.Linear(128,8)\n",
    "        self.liner3 = nn.Linear(8,4)\n",
    "\n",
    "        # self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.liner1(x))\n",
    "        out = self.relu(self.liner2(out))\n",
    "        out = self.relu(self.liner3(out))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN()\n",
    "tensor = torch.rand([1, 8])\n",
    "model(torch.tensor([X[0]], dtype=torch.float32))\n",
    "# \n",
    "\n",
    "# tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_ANN import ANN\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import torch\n",
    "def study(model, X, y, optimizer, losses, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    # counter = 0\n",
    "    # print (\"@@@ Start train model @@@\")\n",
    "    for i, data in enumerate(X):\n",
    "        # counter += 1\n",
    "        image, label = torch.tensor(data,dtype=torch.float32), torch.tensor(y[i],dtype=torch.float32)\n",
    "        image = image.to(device)\n",
    "        label =label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        label_pre = model(image)\n",
    "        # print(label_pre.shape)\n",
    "        loss = losses(label_pre, label)\n",
    "        train_loss += loss.item()\n",
    "        # print(train_loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(preds)\n",
    "    epoch_loss = train_loss / len(X)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, X, y, losses, device):\n",
    "    val_loss = 0\n",
    "    # counter = 0\n",
    "    # print (\"@@@ Start train model @@@\")\n",
    "    for i, data in enumerate(X):\n",
    "        # counter += 1\n",
    "        image, label = torch.tensor(data,dtype=torch.float32), torch.tensor(y[i],dtype=torch.float32)\n",
    "        image = image.to(device)\n",
    "        label =label.to(device)\n",
    "        label_pre = model(image)\n",
    "        # print(label_pre.shape)\n",
    "        loss = losses(label_pre, label)\n",
    "        val_loss += loss.item()\n",
    "        # print(train_loss)\n",
    "        # loss.backward()\n",
    "        # print(preds)\n",
    "    epoch_loss = val_loss / len(X)\n",
    "\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_data(Train_X, Train_y, batch):\n",
    "    X, y = [], []\n",
    "    XX, yy = [], []\n",
    "    j=0\n",
    "    while j < len(Train_y):\n",
    "        X.append(Train_X[j])\n",
    "        y.append(Train_y[j])\n",
    "        if (j+1)%batch==0:\n",
    "            XX.append(X)\n",
    "            yy.append(y)\n",
    "            X, y = [], []\n",
    "        j+=1\n",
    "    return np.array(XX), np.array(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"D:/User/DLBot/scripts/data/angles.csv\")\n",
    "# df.head()\n",
    "data = np.array(df)\n",
    "X = np.array(data[:,0:8], dtype=np.double)/400\n",
    "y = np.array(data[:,8:12], dtype=np.double)/180\n",
    "\n",
    "len(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Val_X, Train_y, Val_y = train_test_split(X, y, test_size=0.2)\n",
    "X_train, y_train = create_batch_data(Train_X, Train_y, 8)\n",
    "X_val, y_val = create_batch_data(Val_X, Val_y, 8)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "import torch.optim as optim\n",
    "\n",
    "# df = pd.read_csv(\"D:/User/Bot_C/Res/scripts/data_control.csv\")\n",
    "\n",
    "# print(y)\n",
    "PATH = \"D:/User/DLBot/scripts/model/model_auto.pt\"\n",
    "learning_rate = 0.001\n",
    "model = ANN()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f\"{total_params:,} total parameters.\")\n",
    "# total_trainable_params = sum(\n",
    "#     p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f\"{total_trainable_params:,} training parameters.\")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# Loss function.\n",
    "# losses = nn.CrossEntropyLoss()\n",
    "losses = nn.MSELoss()\n",
    "loss_tr = []\n",
    "loss_va = []\n",
    "\n",
    "# evaluate a model using repeated k-fold cross-validation\n",
    "for i in range(10000):\n",
    "    train_loss = study(model, X_train,y_train, optimizer, losses, device)\n",
    "    val_loss = val(model,X_val, y_val,losses, device)\n",
    "    loss_tr.append(train_loss)\n",
    "    loss_va.append(val_loss)\n",
    "\n",
    "    if i%10==0:\n",
    "        print('epoch: ',i, 'Train loss: ', train_loss)\n",
    "        print('       ',i, 'Val loss: ', val_loss)\n",
    "\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# path = 'D:/User/DLBot/scripts/data/log.csv'\n",
    "# df = pd.read_csv(path)\n",
    "\n",
    "# df2 = pd.DataFrame(loss, columns=['loss'])\n",
    "# df2 = pd.concat([df, df2])\n",
    "# df2.to_csv(\n",
    "#     path, index=False)\n",
    "plt.title('Sai số góc khớp')\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epoch')\n",
    "\n",
    "plt.plot(loss_tr, label='train_loss')\n",
    "plt.plot(loss_va, label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"D:/User/Bot_C/Res/scripts/data_control.csv\")\n",
    "data = np.array(df_test)\n",
    "X_t = np.array(data[:,0:8], dtype=np.double) \n",
    "y_t = np.array(data[:,8:12], dtype=np.double)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cacular import *\n",
    "data_create = []\n",
    "for idx, dta in enumerate(X_t):\n",
    "    box_1, box_2 = dta[:4], dta[4:]\n",
    "    data_frame = np.hstack(\n",
    "                        [center_box(box_1), center_box(box_2), y_t[idx]])\n",
    "    data_create.append(data_frame)\n",
    "df = pd.read_csv(\"D:/User/Bot_C/Res/scripts/control.csv\")\n",
    "df2 = pd.DataFrame(data_create, columns=['c11', 'c12', 'c21', 'c22', 'q1', 'q2', 'q3', 'q4'])\n",
    "df2 = pd.concat([df, df2])\n",
    "df2.to_csv(\n",
    "    \"D:/User/Bot_C/Res/scripts/control.csv\", index=False)\n",
    "X_t\n",
    "data_create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = ANN()\n",
    "the_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = the_model(torch.tensor([X[:10]],dtype=torch.float32))*180\n",
    "ou = np.array(output.detach().numpy()[0],dtype=np.int8)\n",
    "# len(str(ou[0]))\n",
    "ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tracker.track import *\n",
    "import cv2\n",
    "# url1 = 'http://192.168.2.110/cam-lo.jpg'\n",
    "frame = cv2.imread(\"D:/User/firmware/Screen/hinh-anh-mat-cuoi2-1.png\")\n",
    "\n",
    "speed = 0\n",
    "def callback(data):\n",
    "    global speed\n",
    "    speed = data\n",
    "cv2.namedWindow('test')\n",
    "cv2.createTrackbar('thrs1', 'test', 0, 250, callback)\n",
    "\n",
    "\n",
    "while True:\n",
    "# try:\n",
    "# cap = cv2.VideoCapture(url1)\n",
    "    print(speed)\n",
    "    cv2.imshow(\"image\", frame)\n",
    "    cv2.waitKey(1)\n",
    "# Do whatever you want with contours\n",
    "# cv2.imshow('test', frame)\n",
    "# _, frame = cap.read()\n",
    "# box, frame, area = tracking_sort(frame)\n",
    "# idx = len(box[0])\n",
    "# print(box[0][len(box[0])-1])\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_map(angle, inmax, inmin, outmax, outmin):\n",
    "    return (angle-inmin)*(outmax-outmin)/(inmax-inmin) + outmin\n",
    "\n",
    "areas = 15000\n",
    "different = 15000 - areas\n",
    "speed = convert_map(different, 15000, 0, 255, 150)\n",
    "print(speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_csv = \"D:/User/Bot_C/Res/scripts/data/locals.csv\"\n",
    "\n",
    "idx_name = 2\n",
    "# df = pd.read_csv(path_csv)\n",
    "# data_create = [['imagel_1.png', 'imager_1.png', 'f']]\n",
    "# df2 = pd.DataFrame(data_create, columns=['imagel', 'imager', 'action'])\n",
    "name_l = \"imagel_{}.png\".format(idx_name)\n",
    "name_r = \"imager_{}.png\".format(idx_name)\n",
    "data_frame = []\n",
    "data_out = 1\n",
    "#  = control_keyboard(sv, key)\n",
    "data_frame.append(name_l)\n",
    "data_frame.append(name_r)\n",
    "data_frame.append(data_out)\n",
    "df2 = pd.DataFrame([data_frame], columns=['imagel', 'imager', 'action'])\n",
    "\n",
    "# df2 = pd.DataFrame(data_create, columns=['c11', 'c12', 'c21', 'c22', 'q1', 'q2', 'q3', 'q4'])\n",
    "# df2 = pd.concat([df, df2])\n",
    "df2.to_csv(\n",
    "    path_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_save_l = \"D:/User/data_map/left/\"\n",
    "path_save_r = \"D:/User/data_map/right/\"\n",
    "idx_name = len(os.listdir(path_save_l))\n",
    "\n",
    "print(idx_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# from model_CNN import Net\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "PATH = 'D:/User/DLBot/scripts/model/move_model.pt'\n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5)\n",
    "\n",
    "\n",
    "path_csv = \"D:/User/DLBot/scripts/data/locals.csv\"\n",
    "path_save_l = \"D:/User/data_map/left/\"\n",
    "path_save_r = \"D:/User/data_map/right/\"\n",
    "\n",
    "df = pd.read_csv(path_csv)\n",
    "Train_y = df['action']\n",
    "\n",
    "# X = np.array(df['deceduti']).reshape(-1,1)\n",
    "chuyenDoi = preprocessing.LabelEncoder()\n",
    "chuyenDoi.fit(Train_y)\n",
    "Train_y = chuyenDoi.transform(Train_y)\n",
    "\n",
    "\n",
    "df = np.array(df)\n",
    "\n",
    "Train_X = []\n",
    "print(Train_y)\n",
    "for data in df:\n",
    "    row_data = []\n",
    "    # print(data)\n",
    "    image1 = cv2.imread(path_save_l+data[0])\n",
    "    image2 = cv2.imread(path_save_r+data[1])\n",
    "    \n",
    "    row_data.append(image1)\n",
    "    row_data.append(image2)\n",
    "    \n",
    "    Train_X.append(row_data)\n",
    "    \n",
    "print(np.array(Train_X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Val_X, Train_y, Val_y = train_test_split(Train_X, Train_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Train_X), len(Val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_data(Train_X, Train_y, batch):\n",
    "    X, y = [], []\n",
    "    XX, yy = [], []\n",
    "    j=0\n",
    "    while j < len(Train_y):\n",
    "        X.append(Train_X[j])\n",
    "        y.append(Train_y[j])\n",
    "        if (j+1)%batch==0:\n",
    "            XX.append(X)\n",
    "            yy.append(y)\n",
    "            X, y = [], []\n",
    "        j+=1\n",
    "    return XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = create_batch_data(Train_X, Train_y, 32)\n",
    "tx = np.array(tx,dtype=np.uint8)/255\n",
    "ty = np.array(ty,dtype=np.uint8)\n",
    "tx[:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(Train_y)\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()\n",
    "plt.hist(Val_y)\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch, cv2\n",
    "import torch.nn as nn\n",
    "\n",
    "from model_CNN import Net\n",
    "PATH_best = 'D:/User/DLBot/scripts/model/move_model_new_1.pt'\n",
    "\n",
    "# model = Net()\n",
    "# # model.to(device)\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# error = nn.CrossEntropyLoss()\n",
    "\n",
    "# learning_rate = 0.001\n",
    "# # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# num_epochs = 5\n",
    "# count = 0\n",
    "# # Lists for visualization of loss and accuracy \n",
    "# loss_list = []\n",
    "# iteration_list = []\n",
    "# accuracy_list = []\n",
    "\n",
    "# # Lists for knowing classwise accuracy\n",
    "# predictions_list = []\n",
    "# labels_list = []\n",
    "# predictions_list_train = []\n",
    "# max = 0\n",
    "# for epoch in range(num_epochs):\n",
    "#     correct_train = 0\n",
    "#     total_train = 0\n",
    "#     for i, data in enumerate(Train_X):\n",
    "#         # Transfering images and labels to GPU if available\n",
    "#         # images, labels = images.to(device), labels.to(device)\n",
    "#         image1 = cv2.resize(data[0], [255,255]).transpose([2,0,1])/255\n",
    "#         image2 = cv2.resize(data[1], [255,255]).transpose([2,0,1])/255\n",
    "#         inputs1, inputs2, labels = torch.tensor([image1],dtype=torch.float32), torch.tensor([image2],dtype=torch.float32), torch.tensor([Train_y[i]],dtype=torch.long)\n",
    "        \n",
    "#         # Forward pass \n",
    "#         outputs = model(inputs1, inputs2)\n",
    "#         loss = error(outputs, labels)\n",
    "#         predictions_train = torch.max(outputs, 1)[1]\n",
    "#         predictions_list_train.append(predictions_train)\n",
    "#         correct_train += (predictions_train == labels).sum()\n",
    "\n",
    "#         total_train += len(labels)\n",
    "\n",
    "#         accuracy_train = correct_train * 100 / total_train\n",
    "#         # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         #Propagating the error backward\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # Optimizing the parameters\n",
    "#         optimizer.step()\n",
    "    \n",
    "#         count += 1\n",
    "#         # if not (count % 10):\n",
    "#             # print(\"Iteration: {}, Loss: {}, Accuracy: {} %, Correct: {}\".format(count, loss.data, accuracy_train, correct_train))\n",
    "#     # Testing the model\n",
    "    \n",
    "#         if not (count % 10):    # It's same as \"if count % 50 == 0\"\n",
    "#             total = 0\n",
    "#             correct = 0\n",
    "        \n",
    "#             for j, valda in enumerate(Val_X):\n",
    "#                 # images, labels = images.to(device), labels.to(device)\n",
    "#                 # labels_list.append(labels)\n",
    "            \n",
    "#                 # test = Variable(images.view(100, 1, 28, 28))\n",
    "#                 imagev1 = cv2.resize(valda[0], [255,255]).transpose([2,0,1])/255\n",
    "#                 imagev2 = cv2.resize(valda[1], [255,255]).transpose([2,0,1])/255\n",
    "#                 inputv1, inputv2, labels = torch.tensor([imagev1],dtype=torch.float32), torch.tensor([imagev2],dtype=torch.float32), torch.tensor([Val_y[j]],dtype=torch.long)\n",
    "\n",
    "#                 outputs = model(inputv1, inputv2)\n",
    "            \n",
    "#                 predictions = torch.max(outputs, 1)[1]\n",
    "#                 predictions_list.append(predictions)\n",
    "#                 correct += (predictions == labels).sum()\n",
    "            \n",
    "#                 total += len(labels)\n",
    "            \n",
    "#             accuracy = correct * 100 / total\n",
    "#             loss_list.append(loss.data)\n",
    "#             iteration_list.append(count)\n",
    "#             accuracy_list.append(accuracy)\n",
    "#             if accuracy > max:\n",
    "#                 max = accuracy \n",
    "#                 torch.save(model.state_dict(), PATH_best)\n",
    "#         if not (count % 10):\n",
    "#             print(\"Iteration: {}, Loss: {}, Accuracy: {} %, Train: {}\".format(count, loss.data, accuracy, accuracy_train))\n",
    "# torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list)\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()\n",
    "plt.plot(accuracy_list)\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(Train_X):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        image1 = cv2.resize(data[0], [255,255]).transpose([2,0,1])/255\n",
    "        image2 = cv2.resize(data[1], [255,255]).transpose([2,0,1])/255\n",
    "        inputs1, inputs2, labels = torch.tensor([image1],dtype=torch.float32), torch.tensor([image2],dtype=torch.float32), torch.tensor([Train_y[i]],dtype=torch.long)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs1, inputs2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # if i % 100 == 0:    # print every 2000 mini-batches\n",
    "    print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss}')\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH_best, map_location='cpu'))\n",
    "# Train_X[0][1]\n",
    "out = []\n",
    "for i in range (10):\n",
    "    image1 = cv2.imread(\"D:/User/data_map_0/right/imager_3.png\")\n",
    "    image2 = cv2.imread(\"D:/User/data_map_0/left/imagel_3.png\")\n",
    "    image1 = cv2.resize(image1, [256,256]).transpose([2,0,1])/256\n",
    "    image2 = cv2.resize(image2, [256,256]).transpose([2,0,1])/256\n",
    "    image1, image2 = torch.tensor([image1],dtype=torch.float32), torch.tensor([image2],dtype=torch.float32)\n",
    "    outputs = net(image1, image2)\n",
    "    print(outputs)\n",
    "    cost, predicted = torch.max(outputs, 1)\n",
    "    print(cost)\n",
    "    out.append(np.array(predicted, dtype=np.uint8)[0])\n",
    "chuyenDoi.inverse_transform(np.array(out, dtype=np.uint8))\n",
    "\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import time\n",
    "\n",
    "shortcuts = {\n",
    "        \"Key1\":\"a\",\n",
    "        \"Key2\":\"b\",\n",
    "        \"Key3\":\"c\",\n",
    "        }\n",
    "\n",
    "def showText(text):\n",
    "    print(text)\n",
    "    \n",
    "for text, hotkey in shortcuts.items():\n",
    "    keyboard.on_press_key(hotkey, lambda _:showText(text))\n",
    "\n",
    "keyboard.on_press_key(\"d\", lambda _:showText(\"Key4\"))\n",
    "keyboard.on_press_key(\"e\", lambda _:showText(\"Key5\"))\n",
    "\n",
    "while 1:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n",
      "      0\n",
      "0  32.0\n",
      "    0        1        2       3       4\n",
      "0  32  0.58625  0.59125  0.2875  0.2075\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2      3       4\n",
      "0  32  0.4275  0.6175  0.285  0.2175\n",
      "    0       1     2       3       4\n",
      "0  32  0.4175  0.62  0.2725  0.2175\n",
      "    0    1     2       3       4\n",
      "0  32  0.4  0.63  0.2825  0.2125\n",
      "    0       1     2       3       4\n",
      "0  32  0.3975  0.63  0.2875  0.2125\n",
      "    0       1       2     3      4\n",
      "0  32  0.5475  0.6275  0.27  0.225\n",
      "    0       1     2     3      4\n",
      "0  32  0.5475  0.63  0.27  0.225\n",
      "    0       1       2     3       4\n",
      "0  32  0.5625  0.6275  0.29  0.2075\n",
      "    0      1     2       3     4\n",
      "0  32  0.565  0.63  0.2975  0.21\n",
      "    0       1     2      3      4\n",
      "0  32  0.5375  0.62  0.355  0.255\n",
      "    0       1     2       3       4\n",
      "0  32  0.2875  0.62  0.2425  0.1725\n",
      "    0       1     2       3       4\n",
      "0  32  0.2875  0.62  0.2425  0.1725\n",
      "    0     1      2      3      4\n",
      "0  32  0.32  0.625  0.215  0.165\n",
      "    0     1      2      3       4\n",
      "0  32  0.32  0.625  0.215  0.1675\n",
      "    0     1      2      3       4\n",
      "0  32  0.32  0.625  0.215  0.1675\n",
      "    0     1      2      3       4\n",
      "0  32  0.32  0.625  0.215  0.1675\n",
      "    0     1      2      3     4\n",
      "0  32  0.32  0.625  0.215  0.17\n",
      "    0     1      2      3     4\n",
      "0  32  0.32  0.625  0.215  0.17\n",
      "    0      1      2      3      4\n",
      "0  32  0.535  0.615  0.355  0.255\n",
      "    0     1      2      3       4\n",
      "0  32  0.32  0.625  0.215  0.1675\n",
      "    0     1      2      3     4\n",
      "0  32  0.32  0.625  0.215  0.17\n",
      "    0       1      2      3     4\n",
      "0  32  0.3175  0.625  0.215  0.17\n",
      "    0       1      2       3       4\n",
      "0  32  0.3175  0.625  0.2175  0.1675\n",
      "    0       1      2       3     4\n",
      "0  32  0.3175  0.625  0.2175  0.17\n",
      "    0       1      2       3     4\n",
      "0  32  0.3175  0.625  0.2175  0.17\n",
      "    0       1      2       3     4\n",
      "0  32  0.3175  0.625  0.2175  0.17\n",
      "    0     1      2      3       4\n",
      "0  32  0.32  0.625  0.215  0.1675\n",
      "    0     1      2      3      4\n",
      "0  32  0.32  0.625  0.205  0.175\n",
      "    0     1      2      3      4\n",
      "0  32  0.32  0.625  0.205  0.175\n",
      "    0       1      2     3       4\n",
      "0  32  0.5325  0.615  0.36  0.2575\n",
      "    0      1       2     3     4\n",
      "0  32  0.695  0.5725  0.12  0.09\n",
      "    0       1       2     3     4\n",
      "0  32  0.6975  0.5725  0.12  0.09\n",
      "    0      1       2       3       4\n",
      "0  32  0.695  0.5725  0.1175  0.0925\n",
      "    0      1       2     3      4\n",
      "0  32  0.295  0.5725  0.13  0.095\n",
      "    0       1       2     3       4\n",
      "0  32  0.2975  0.5725  0.13  0.0975\n",
      "    0       1       2      3      4\n",
      "0  32  0.2975  0.5725  0.125  0.095\n",
      "    0       1      2      3       4\n",
      "0  32  0.5375  0.615  0.355  0.2525\n",
      "    0      1      2      3      4\n",
      "0  32  0.535  0.615  0.355  0.255\n",
      "    0       1       2      3       4\n",
      "0  32  0.6175  0.6525  0.495  0.3475\n",
      "    0       1       2      3     4\n",
      "0  32  0.6075  0.6525  0.475  0.34\n",
      "    0       1     2     3     4\n",
      "0  32  0.4675  0.62  0.35  0.26\n",
      "    0    1      2       3     4\n",
      "0  32  0.5  0.615  0.3025  0.25\n",
      "    0        1       2       3      4\n",
      "0  32  0.69125  0.5925  0.3225  0.235\n",
      "    0       1       2       3       4\n",
      "0  32  0.5425  0.5675  0.2575  0.1825\n",
      "    0      1       2       3      4\n",
      "0  32  0.545  0.5675  0.2575  0.185\n",
      "    0     1      2     3      4\n",
      "0  32  0.49  0.615  0.24  0.175\n",
      "    0       1       2       3       4\n",
      "0  32  0.5225  0.6025  0.2475  0.2125\n",
      "    0       1    2    3       4\n",
      "0  32  0.4875  0.6  0.3  0.2275\n",
      "    0     1      2      3      4\n",
      "0  32  0.37  0.625  0.375  0.295\n",
      "    0       1       2       3       4\n",
      "0  32  0.3675  0.6225  0.3725  0.2925\n",
      "    0       1        2     3       4\n",
      "0  32  0.6975  0.59375  0.32  0.2325\n",
      "    0       1       2      3      4\n",
      "0  32  0.7675  0.7175  0.465  0.485\n",
      "    0        1      2       3     4\n",
      "0  32  0.76875  0.725  0.4625  0.49\n",
      "    0      1      2      3       4\n",
      "0  32  0.765  0.725  0.465  0.5125\n",
      "    0     1     2       3      4\n",
      "0  32  0.55  0.66  0.4675  0.375\n",
      "    0       1     2     3      4\n",
      "0  32  0.7875  0.61  0.41  0.325\n",
      "    0      1     2       3      4\n",
      "0  32  0.515  0.62  0.2925  0.205\n",
      "    0     1      2       3     4\n",
      "0  32  0.39  0.565  0.1975  0.15\n",
      "    0       1      2       3       4\n",
      "0  32  0.4775  0.595  0.2925  0.2325\n",
      "    0     1      2       3     4\n",
      "0  32  0.48  0.595  0.2925  0.23\n",
      "    0     1       2       3       4\n",
      "0  32  0.29  0.5675  0.2175  0.1575\n",
      "    0        1     2       3     4\n",
      "0  32  0.52125  0.63  0.3925  0.28\n",
      "    0     1     2      3       4\n",
      "0  32  0.53  0.55  0.175  0.1275\n",
      "    0     1        2      3       4\n",
      "0  32  0.47  0.55875  0.185  0.1425\n",
      "    0      1      2      3      4\n",
      "0  32  0.345  0.675  0.395  0.305\n",
      "    0       1      2       3      4\n",
      "0  32  0.3475  0.675  0.4025  0.305\n",
      "    0       1       2      3      4\n",
      "0  32  0.5375  0.6025  0.245  0.195\n",
      "    0       1       2       3      4\n",
      "0  32  0.5375  0.6025  0.2525  0.195\n",
      "    0      1       2      3      4\n",
      "0  32  0.595  0.5775  0.215  0.165\n",
      "    0     1       2      3     4\n",
      "0  32  0.55  0.6975  0.535  0.38\n",
      "    0      1        2      3       4\n",
      "0  32  0.515  0.63375  0.395  0.2825\n",
      "    0       1     2     3     4\n",
      "0  32  0.6825  0.75  0.63  0.48\n",
      "    0       1       2       3      4\n",
      "0  32  0.1125  0.6125  0.2225  0.195\n",
      "    0     1       2       3     4\n",
      "0  32  0.51  0.6375  0.3325  0.25\n",
      "    0       1       2      3      4\n",
      "0  32  0.5975  0.5775  0.175  0.135\n",
      "    0       1     2       3      4\n",
      "0  32  0.6875  0.55  0.1575  0.115\n",
      "    0       1       2       3       4\n",
      "0  32  0.0525  0.5725  0.1075  0.0925\n",
      "    0       1       2       3     4\n",
      "0  32  0.3275  0.6375  0.2975  0.22\n",
      "    0       1       2       3      4\n",
      "0  32  0.3075  0.6375  0.2975  0.215\n",
      "    0      1     2       3       4\n",
      "0  32  0.445  0.66  0.3575  0.2775\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0      1       2     3       4\n",
      "0  32  0.615  0.5325  0.42  0.3325\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2     3       4\n",
      "0  32  0.4475  0.6575  0.36  0.2825\n",
      "    0       1       2       3       4\n",
      "0  32  0.3525  0.6075  0.2075  0.1575\n",
      "    0       1       2     3       4\n",
      "0  32  0.3525  0.6075  0.21  0.1575\n",
      "    0       1       2     3       4\n",
      "0  32  0.3525  0.6075  0.21  0.1575\n",
      "    0       1     2     3     4\n",
      "0  32  0.6125  0.64  0.42  0.32\n",
      "    0       1       2     3       4\n",
      "0  32  0.3525  0.6075  0.21  0.1575\n",
      "    0       1       2     3       4\n",
      "0  32  0.3525  0.6075  0.21  0.1575\n",
      "    0     1       2       3       4\n",
      "0  32  0.35  0.6075  0.2025  0.1575\n",
      "    0     1      2       3       4\n",
      "0  32  0.35  0.605  0.2025  0.1575\n",
      "    0     1      2       3       4\n",
      "0  32  0.35  0.605  0.2025  0.1575\n",
      "    0       1       2      3     4\n",
      "0  32  0.3525  0.6075  0.205  0.16\n",
      "    0       1       2      3     4\n",
      "0  32  0.3525  0.6075  0.205  0.16\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1      2      3       4\n",
      "0  32  0.3525  0.605  0.205  0.1575\n",
      "    0       1       2      3     4\n",
      "0  32  0.3925  0.6225  0.245  0.19\n",
      "    0       1       2      3     4\n",
      "0  32  0.3925  0.6225  0.245  0.19\n",
      "    0       1       2      3     4\n",
      "0  32  0.3925  0.6225  0.245  0.19\n",
      "    0       1     2      3       4\n",
      "0  32  0.4475  0.46  0.265  0.2175\n",
      "    0       1       2      3       4\n",
      "0  32  0.3575  0.6275  0.255  0.2025\n",
      "    0       1       2      3       4\n",
      "0  32  0.3575  0.6275  0.255  0.2025\n",
      "    0        1        2       3       4\n",
      "0  32  0.37625  0.56875  0.1975  0.1525\n",
      "    0       1     2      3      4\n",
      "0  32  0.4075  0.42  0.265  0.195\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0       1       2       3      4\n",
      "0  32  0.4125  0.6075  0.2175  0.165\n",
      "    0      1       2     3     4\n",
      "0  32  0.625  0.7425  0.41  0.27\n",
      "    0        1     2       3      4\n",
      "0  32  0.59875  0.74  0.4225  0.265\n",
      "    0        1        2       3       4\n",
      "0  32  0.54875  0.73625  0.4075  0.2725\n",
      "    0      1        2     3       4\n",
      "0  32  0.455  0.71625  0.37  0.2625\n",
      "    0       1       2     3      4\n",
      "0  32  0.4125  0.7125  0.38  0.255\n",
      "    0        1      2       3     4\n",
      "0  32  0.38875  0.705  0.3925  0.25\n",
      "    0      1       2    3     4\n",
      "0  32  0.275  0.7175  0.4  0.25\n",
      "    0        1        2       3       4\n",
      "0  32  0.23625  0.72125  0.4075  0.2575\n",
      "    0        1     2       3      4\n",
      "0  32  0.19875  0.72  0.3925  0.265\n",
      "    0        1     2       3      4\n",
      "0  32  0.18625  0.71  0.3675  0.265\n",
      "    0        1        2       3       4\n",
      "0  32  0.24375  0.69625  0.3625  0.2425\n",
      "    0        1       2       3     4\n",
      "0  32  0.86375  0.7375  0.2725  0.27\n",
      "    0       1        2     3       4\n",
      "0  32  0.4475  0.63875  0.26  0.1775\n",
      "    0        1      2       3     4\n",
      "0  32  0.50125  0.635  0.2575  0.18\n",
      "    0      1     2     3     4\n",
      "0  32  0.505  0.63  0.26  0.18\n",
      "    0       1       2     3     4\n",
      "0  32  0.5125  0.6275  0.26  0.18\n",
      "    0        1        2       3       4\n",
      "0  32  0.55375  0.62625  0.2625  0.1825\n",
      "    0        1       2       3      4\n",
      "0  32  0.63375  0.6275  0.2525  0.175\n",
      "    0       1        2      3       4\n",
      "0  32  0.7125  0.62375  0.235  0.1675\n",
      "    0        1        2       3       4\n",
      "0  32  0.73875  0.61875  0.2375  0.1625\n",
      "    0        1        2       3       4\n",
      "0  32  0.78125  0.61375  0.2425  0.1525\n",
      "    0        1        2       3       4\n",
      "0  32  0.78625  0.61875  0.2375  0.1625\n",
      "    0        1        2       3       4\n",
      "0  32  0.86375  0.74375  0.2725  0.2825\n",
      "    0        1      2       3     4\n",
      "0  32  0.78875  0.615  0.2425  0.16\n",
      "    0     1        2     3       4\n",
      "0  32  0.79  0.61375  0.24  0.1625\n",
      "    0        1        2       3       4\n",
      "0  32  0.80125  0.61125  0.2375  0.1625\n",
      "    0        1       2       3      4\n",
      "0  32  0.81125  0.6075  0.2325  0.155\n",
      "    0      1        2      3       4\n",
      "0  32  0.815  0.59875  0.235  0.1475\n",
      "    0     1        2      3       4\n",
      "0  32  0.78  0.59625  0.245  0.1575\n",
      "    0        1      2       3      4\n",
      "0  32  0.73375  0.605  0.2425  0.165\n",
      "    0        1        2       3       4\n",
      "0  32  0.67875  0.60125  0.2425  0.1575\n",
      "    0        1        2       3       4\n",
      "0  32  0.64125  0.60375  0.2475  0.1675\n",
      "    0        1       2       3      4\n",
      "0  32  0.58375  0.6075  0.2575  0.175\n",
      "    0        1        2       3       4\n",
      "0  32  0.86625  0.75125  0.2675  0.2975\n",
      "    0        1    2       3      4\n",
      "0  32  0.51125  0.6  0.2575  0.165\n",
      "    0        1     2       3     4\n",
      "0  32  0.45875  0.59  0.2625  0.17\n",
      "    0       1      2      3      4\n",
      "0  32  0.4075  0.585  0.265  0.165\n",
      "    0        1        2       3       4\n",
      "0  32  0.37375  0.58125  0.2675  0.1625\n",
      "    0        1        2       3       4\n",
      "0  32  0.36375  0.58875  0.2675  0.1725\n",
      "    0        1      2       3      4\n",
      "0  32  0.30625  0.585  0.2675  0.165\n",
      "    0       1        2      3       4\n",
      "0  32  0.2725  0.58625  0.265  0.1675\n",
      "    0       1       2      3     4\n",
      "0  32  0.2475  0.5825  0.275  0.17\n",
      "    0       1     2     3      4\n",
      "0  32  0.2025  0.58  0.26  0.175\n",
      "    0       1       2     3      4\n",
      "0  32  0.1925  0.5775  0.27  0.175\n",
      "    0       1        2      3       4\n",
      "0  32  0.8475  0.74625  0.305  0.2975\n",
      "    0       1        2      3       4\n",
      "0  32  0.1625  0.57875  0.275  0.1725\n",
      "    0        1       2       3      4\n",
      "0  32  0.81375  0.7525  0.3725  0.275\n",
      "    0      1     2      3     4\n",
      "0  32  0.735  0.75  0.435  0.27\n",
      "    0        1        2       3       4\n",
      "0  32  0.68375  0.75125  0.4275  0.2875\n",
      "    0       1      2     3     4\n",
      "0  32  0.6125  0.745  0.41  0.28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "# pathh = \"C:/Users/Hero/Downloads/data_rubish/labels/Val/\"\n",
    "\n",
    "type_folder = 'Val/'\n",
    "\n",
    "new_image_paths = \"C:/Users/Hero/Downloads/data_rubishs/images/\"+type_folder\n",
    "new_label_paths = \"C:/Users/Hero/Downloads/data_rubishs/labels/\"+type_folder\n",
    "\n",
    "old_image_paths = \"C:/Users/Hero/Downloads/data_rubish/images/\"+type_folder\n",
    "old_label_paths= \"C:/Users/Hero/Downloads/data_rubish/labels/\"+type_folder\n",
    "try:\n",
    "  os.makedirs(new_image_paths)\n",
    "  os.makedirs(new_label_paths)\n",
    "except:\n",
    "  pass\n",
    "count = 0\n",
    "lisdir = os.listdir(old_label_paths)\n",
    "\n",
    "print(len(lisdir))\n",
    "for filename in lisdir:\n",
    "\n",
    "  image_name = filename.replace('.txt','.png')\n",
    "\n",
    "  old_image_path = os.path.join(old_image_paths, image_name)\n",
    "  old_label_path = os.path.join(old_label_paths, filename)\n",
    "\n",
    "  new_image_name = (6-len(str(count)))*'0' + str(count) + \".png\"\n",
    "  new_label_name = (6-len(str(count)))*'0' + str(count) + \".txt\"\n",
    "\n",
    "  try:\n",
    "    old_label = pd.read_csv(old_label_path, sep=\" \", header=None)\n",
    "    # label_data = np.array(old_label)\n",
    "\n",
    "    label_data = old_label\n",
    "  except:\n",
    "    print(\"Emtry\")\n",
    "    continue\n",
    "\n",
    "  old_image = cv2.imread(old_image_path)\n",
    "\n",
    "  # print(len(label_data))\n",
    "\n",
    "  # if len(label_data) > 1:\n",
    "  #   print(label_data.loc[1,1])\n",
    "\n",
    "  for i in range(len(label_data)):\n",
    "    label_data.loc[i,0] = 32\n",
    "  data_frame = pd.DataFrame(label_data)\n",
    "  print(data_frame)\n",
    "\n",
    "  new_image_path = os.path.join(new_image_paths, new_image_name)\n",
    "  new_label_path = os.path.join(new_label_paths, new_label_name)\n",
    "\n",
    "  # print(old_image)\n",
    "  try:\n",
    "    cv2.imwrite(new_image_path, old_image)\n",
    "  except:\n",
    "    continue\n",
    "  # print(\"Image: \", old_image_path)\n",
    "  # print(\"Label: \", old_label_path)\n",
    "  data_frame.to_csv(new_label_path, sep=' ', index=False, header=False)\n",
    "\n",
    "\n",
    "  count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_label[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "count = 0\n",
    "pathh_image = \"C:/Users/Hero/Downloads/data_rubish/images/Val\"\n",
    "pathh_label = \"C:/Users/Hero/Downloads/data_rubish/labels/Val/\"\n",
    "for filename in lisdir:\n",
    "\n",
    "    file_ext = os.path.splitext(filename)[1]\n",
    "    name = '0000' + str(count)\n",
    "    old_file_label = os.path.join(dir_path, filename)\n",
    "    new_file_label = os.path.join(dir_path, new_filename)\n",
    "    \n",
    "    old_file_image = os.path.join(dir_path, filename)\n",
    "    new_file_imaeg = os.path.join(dir_path, new_filename)\n",
    "    \n",
    "    os.rename(oldFileName, newFileName)\n",
    "    os.rename(oldFileName, newFileName) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchview import draw_graph\n",
    "from model_CNN import Net\n",
    "# import \n",
    "\n",
    "net = Net()\n",
    "\n",
    "model_graph = draw_graph(net, input_size=((1,3,256,256),(1,3,256,256)), expand_nested=True)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_ANN import ANN\n",
    "from model_CNNM import Net\n",
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "\n",
    "\n",
    "model = ANN(8)\n",
    "# model = Net()\n",
    "\n",
    "model_graph = draw_graph(model, input_size=((1,8)), expand_nested=True)\n",
    "\n",
    "# model_graph = draw_graph(model, input_size=((1,3,255,255),(1,3,255,255)), expand_nested=True)\n",
    "model_graph.visual_graph\n",
    "# graphviz.set_jupyter_format('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1189/1189 [00:34<00:00, 34.43it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "# from model_CNN import Net\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATH = '/content/drive/MyDrive/data_map/move_model_new_2.pt'\n",
    "\n",
    "path_csv = \"D:/User/DLBot/scripts/data/locals.csv\"\n",
    "path_save_l = \"D:/User/data_map_1/left/\"\n",
    "path_save_r = \"D:/User/data_map_1/right/\"\n",
    "\n",
    "df = pd.read_csv(path_csv)\n",
    "data_y = df['action']\n",
    "\n",
    "# X = np.array(df['deceduti']).reshape(-1,1)\n",
    "chuyenDoi = preprocessing.LabelEncoder()\n",
    "chuyenDoi.fit(data_y)\n",
    "data_y = chuyenDoi.transform(data_y)\n",
    "\n",
    "\n",
    "df = np.array(df)\n",
    "\n",
    "data_X = []\n",
    "print(data_y)\n",
    "for i in tqdm(range(len(df))):\n",
    "    row_data = []\n",
    "    # print(data)\n",
    "    image1 = cv2.imread(path_save_l+df[i][0])\n",
    "    image2 = cv2.imread(path_save_r+df[i][1])\n",
    "\n",
    "    image1 = cv2.resize(image1, [256,256])\n",
    "    image2 = cv2.resize(image2, [256,256])\n",
    "\n",
    "    row_data.append(image1.transpose([2,0,1]))\n",
    "    row_data.append(image2.transpose([2,0,1]))\n",
    "\n",
    "    data_X.append(row_data)\n",
    "with open('D:/User/DLBot/scripts/data/category.npy', 'wb') as f:\n",
    "    np.save(f, np.array(np.array(data_X)))\n",
    "with open('D:/User/DLBot/scripts/data/labels.npy', 'wb') as f:\n",
    "    np.save(f, np.array(np.array(data_y)))\n",
    "\n",
    "# print(np.array(data_X).shape)\n",
    "# print(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data_y)\n",
    "plt.title(\"Histogram Train\")\n",
    "plt.show()\n",
    "# plt.hist(Val_y)\n",
    "# plt.title(\"Histogram Val\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "# # Define x, y, and xnew to resample at.\n",
    "# x = np.linspace(0, 10, num=11, endpoint=True)\n",
    "# y = np.cos(-x**2/9.0)\n",
    "# xnew = np.linspace(0, 10, num=41, endpoint=True)\n",
    "\n",
    "# # Define interpolators.\n",
    "# f_linear = interp1d(x, y)\n",
    "# f_cubic = interp1d(x, y, kind='cubic')\n",
    "\n",
    "# # Plot.\n",
    "# plt.plot(x, y, 'o', label='data')\n",
    "# plt.plot(xnew, f_linear(xnew), '-', label='linear')\n",
    "# plt.plot(xnew, f_cubic(xnew), '--', label='cubic')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_islle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
